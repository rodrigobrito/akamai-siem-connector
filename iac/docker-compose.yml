version: "3"

services:
  # Base Apache kafka image to be used to construct the broker and zookeeper.
  base-kafka:
    build: ${HOME_DIR}/base-kafka
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/base-kafka:${BUILD_VERSION}
    profiles:
      - build

  # Zookeeper image used to control the Apache Kafka Broker instances.
  zookeeper:
    build:
      context: ${HOME_DIR}/kafka/zookeeper
      args:
        - REPOSITORY_URL=${REPOSITORY_URL}
        - REPOSITORY_ID=${REPOSITORY_ID}
        - BUILD_VERSION=${BUILD_VERSION}
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/zookeeper:${BUILD_VERSION}
    container_name: zookeeper
    hostname: zookeeper
    # ports:
    #   - "2181:2181"
    #   - "8080:8080"
    volumes:
      - ${HOME_DIR}/kafka/zookeeper/etc/zookeeper.properties:/home/kafka/etc/zookeeper.properties
    profiles:
      - run
      - build

  # Apache Kafka Broker image used to receive the events collected.
  kafka-broker:
    build:
      context: ${HOME_DIR}/kafka/broker
      args:
        - REPOSITORY_URL=${REPOSITORY_URL}
        - REPOSITORY_ID=${REPOSITORY_ID}
        - BUILD_VERSION=${BUILD_VERSION}
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/kafka-broker:${BUILD_VERSION}
    container_name: kafka-broker
    hostname: kafka-broker
    # ports:
    #   - "9092:9092"
    volumes:
      - ${HOME_DIR}/kafka/broker/etc/server.properties:/home/kafka/etc/server.properties
    depends_on:
      - zookeeper
    profiles:
      - run
      - build

  # UI for Apache Kafka Broker.
  kafka-broker-ui:
    image: provectuslabs/kafka-ui:latest
    environment:
      - KAFKA_CLUSTERS_0_NAME=kafka-broker
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka-broker:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
      - AUTH_TYPE="Login Form"
      - SPRING_SECURITY_USER_NAME=admin
      - SPRING_SECURITY_USER_PASSWORD=admin
      - SERVER_SERVLET_CONTEXT_PATH=
    container_name: kafka-broker-ui
    hostname: kafka-broker-ui
    # ports:
    #   - "8080:8080"
    depends_on:
      - kafka-broker
    profiles:
      - run

  # Scheduler that defines the jobs for the consumer.
  scheduler:
    build: ${HOME_DIR}/scheduler
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/akamai-siem-scheduler:${BUILD_VERSION}
    container_name: scheduler
    hostname: scheduler
    # ports:
    #   - "1883:1883"
    volumes:
      - ${HOME_DIR}/scheduler/etc/settings.json:/home/scheduler/etc/settings.json
    profiles:
      - build
      - run

  # Base consumer image used to construct Akamai SIEM consumer. It also generates mock events.
  base-consumer:
    build: ${HOME_DIR}/base-consumer
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/base-akamai-siem-consumer:${BUILD_VERSION}
    environment:
      - NODE_OPTIONS="--max-old-space-size=1024"
    container_name: base-consumer
    hostname: base-consumer
    volumes:
      - ${HOME_DIR}/base-consumer/etc/settings.json:/home/consumer/etc/settings.json
    depends_on:
      - scheduler
    profiles:
      - build
      - run

  # Consumer that collects from Akamai SIEM.
  consumer:
    build:
      context: ${HOME_DIR}/consumer
      args:
        - REPOSITORY_URL=${REPOSITORY_URL}
        - REPOSITORY_ID=${REPOSITORY_ID}
        - BUILD_VERSION=${BUILD_VERSION}
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/akamai-siem-consumer:${BUILD_VERSION}
    # environment:
    #   - NODE_OPTIONS="--max-old-space-size=1024"
    # container_name: consumer
    # hostname: consumer
    # volumes:
    #   - ${HOME}/.edgerc:/home/consumer/etc/.edgerc
    #   - ${HOME_DIR}/consumer/etc/settings.json:/home/consumer/etc/settings.json
    # depends_on:
    #   - scheduler
    profiles:
    #  - run
      - build

  # Base processor image used to constructor processors to consume Akamai SIEM events.
  base-processor:
    build: ${HOME_DIR}/base-processor
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/base-akamai-siem-processor:${BUILD_VERSION}
    # environment:
    #   - NODE_OPTIONS="--max-old-space-size=1024"
    # container_name: base-processor
    # hostname: base-processor
    # volumes:
    #   - ${HOME_DIR}/base-processor/etc/settings.json:/home/processor/etc/settings.json
    # depends_on:
    #   - scheduler
    profiles:
    #  - run
      - build

  # Processor that stores events in Apache kafka Broker.
  processor-kafka:
    build:
      context: ${HOME_DIR}/processor-kafka
      args:
        - REPOSITORY_URL=${REPOSITORY_URL}
        - REPOSITORY_ID=${REPOSITORY_ID}
        - BUILD_VERSION=${BUILD_VERSION}
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/akamai-siem-processor-kafka:${BUILD_VERSION}
    environment:
      - NODE_OPTIONS="--max-old-space-size=1024"
    container_name: processor-kafka
    hostname: processor-kafka
    volumes:
      - ${HOME_DIR}/processor-kafka/etc/settings.json:/home/processor/etc/settings.json
    depends_on:
      - scheduler
    profiles:
      - run
      - build

  # Convert events stored in json format in Apache Kafka Broker.
  json-converter:
    build: ${HOME_DIR}/json-converter
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/akamai-siem-json-converter:${BUILD_VERSION}
    environment:
      - "JAVA_OPTS=-Xms1024m -Xmx1024m"
    container_name: json-converter
    hostname: json-converter
    volumes:
      - ${HOME_DIR}/json-converter/src/main/resources/etc/settings.json:/home/json-converter/etc/settings.json
    depends_on:
      - kafka-broker
    profiles:
      - run
      - build

  # Logstash image used to collect the events from Apache Kafka Broker and store into opensearch. Use this only for
  # troubleshooting or testing.
  logstash-kafka-opensearch:
    image: opensearchproject/logstash-oss-with-opensearch-output-plugin:7.16.3
    environment:
      - "LS_JAVA_OPTS=-Xms1024m -Xmx1024m"
    container_name: logstash-kafka-opensearch
    hostname: logstash-kafka-opensearch
    volumes:
      - ${HOME_DIR}/logstash-kafka-opensearch/etc/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - kafka-broker
      - opensearch
    profiles:
      - run

  # Logstash image used to collect the events from Apache Kafka Broker and store into Microsoft Sentinel.
  logstash-kafka-mssentinel:
    build: ${HOME_DIR}/logstash-kafka-mssentinel
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/akamai-siem-logstash-kafka-mssentinel:${BUILD_VERSION}
    # environment:
    #   - "LS_JAVA_OPTS=-Xms1024m -Xmx1024m"
    #   - WORKSPACE_ID=workspace_id
    #   - WORKSPACE_KEY=workspace_key
    #   - TABLE_NAME=table_name
    # container_name: logstash-kafka-mssentinel
    # hostname: logstash-kafka-mssentinel
    # volumes:
    #   - ${HOME_DIR}/logstash-kafka-mssentinel/etc/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    # depends_on:
    #   - kafka-broker
    profiles:
    #  - run
      - build

  # Opensearch database to store the collected events. Use this only for troubleshooting or testing.
  opensearch:
    image: opensearchproject/opensearch:2.1.0
    environment:
      - discovery.type=single-node
      - node.name=opensearch
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms1024m -Xmx1024m"
    container_name: opensearch
    hostname: opensearch
    # ports:
    #   - "9200:9200"
    #   - "9600:9600"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    profiles:
      - run

  # Opensearch dashboards image used to view/filter the collected events. Use this only for troubleshooting or testing.
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.1.0
    container_name: opensearch-dashboards
    hostname: opensearch-dashboards
    environment:
      - OPENSEARCH_HOSTS=["https://opensearch:9200"]
    # ports:
    #   - "5601:5601"
    depends_on:
      - opensearch
    profiles:
      - run

  # Ingress (HTTPs delivery).
  ingress:
    build: ${HOME_DIR}/ingress
    image: ${REPOSITORY_URL}/${REPOSITORY_ID}/akamai-siem-ingress:${BUILD_VERSION}
    container_name: ingress
    hostname: ingress
    # environment:
    #   - QUEUE_DOMAIN=queue.akamai.siem
    #   - DASHBOARDS_DOMAIN=dashboards.akamai.siem
    ports:
      - "8080:80"
    #  - "8443:443"
    volumes:
#      - ${HOME_DIR}/ingress/etc/nginx/http.d/default.conf:/home/ingress/etc/nginx/http.d/default.conf
      - ${HOME_DIR}/ingress/etc/nginx/http.d/opensearch-dashboards.conf:/home/ingress/etc/nginx/http.d/opensearch-dashboards.conf
#      - ${HOME_DIR}/ingress/etc/ssl/certs/cert.crt:/home/ingress/etc/ssl/certs/cert.crt
#      - ${HOME_DIR}/ingress/etc/ssl/private/cert.key:/home/ingress/etc/ssl/private/cert.key
    depends_on:
      - kafka-broker-ui
      - opensearch-dashboards
    profiles:
      - run
      - build